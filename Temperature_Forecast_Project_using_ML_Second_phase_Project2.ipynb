{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8KV7ZZmZTlHP"
   },
   "source": [
    "# Temperature Forecast Project using ML\n",
    "**Project Description**\n",
    "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.\n",
    "\n",
    "**Attribute Information:**\n",
    "For more information, read [Cho et al, 2020].\n",
    "1. station - used weather station number: 1 to 25\n",
    "2. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
    "3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
    "4. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
    "5. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
    "6. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
    "7. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
    "8. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
    "9. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
    "10. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
    "11. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
    "12. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
    "13. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
    "14. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
    "15. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
    "16. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
    "17. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
    "18. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
    "19. lat - Latitude (Â°): 37.456 to 37.645\n",
    "20. lon - Longitude (Â°): 126.826 to 127.135\n",
    "21. DEM - Elevation (m): 12.4 to 212.3\n",
    "22. Slope - Slope (Â°): 0.1 to 5.2\n",
    "23. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
    "24. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
    "25. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
    "\n",
    "You have to build separate models that can predict the minimum temperature for the next day and the maximum temperature for the next day based on the details provided in the dataset.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y9cTuQ7aTwDZ"
   },
   "source": [
    "**Dataset Link-**\n",
    "•\thttps://github.com/FlipRoboTechnologies/ML_-Datasets/blob/main/Temperature%20Forecast/temperature.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z330L2hmci4k"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rasterio\n",
      "  Obtaining dependency information for rasterio from https://files.pythonhosted.org/packages/03/d9/40d44154946a55e8fe63b21d44120dae02f4f62500338d09ee0d29d59025/rasterio-1.3.10-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading rasterio-1.3.10-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting affine (from rasterio)\n",
      "  Obtaining dependency information for affine from https://files.pythonhosted.org/packages/0b/f7/85273299ab57117850cc0a936c64151171fac4da49bc6fba0dad984a7c5f/affine-2.4.0-py3-none-any.whl.metadata\n",
      "  Downloading affine-2.4.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from rasterio) (23.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from rasterio) (2023.7.22)\n",
      "Requirement already satisfied: click>=4.0 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from rasterio) (8.0.4)\n",
      "Collecting cligj>=0.5 (from rasterio)\n",
      "  Obtaining dependency information for cligj>=0.5 from https://files.pythonhosted.org/packages/73/86/43fa9f15c5b9fb6e82620428827cd3c284aa933431405d1bcf5231ae3d3e/cligj-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading cligj-0.7.2-py3-none-any.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from rasterio) (1.24.3)\n",
      "Collecting snuggs>=1.4.1 (from rasterio)\n",
      "  Obtaining dependency information for snuggs>=1.4.1 from https://files.pythonhosted.org/packages/cc/0e/d27d6e806d6c0d1a2cfdc5d1f088e42339a0a54a09c3343f7f81ec8947ea/snuggs-1.4.7-py3-none-any.whl.metadata\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting click-plugins (from rasterio)\n",
      "  Obtaining dependency information for click-plugins from https://files.pythonhosted.org/packages/e9/da/824b92d9942f4e472702488857914bdd50f73021efea15b4cad9aca8ecef/click_plugins-1.1.1-py2.py3-none-any.whl.metadata\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: setuptools in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from rasterio) (68.0.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from click>=4.0->rasterio) (0.4.6)\n",
      "Requirement already satisfied: pyparsing>=2.1.6 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from snuggs>=1.4.1->rasterio) (3.0.9)\n",
      "Downloading rasterio-1.3.10-cp311-cp311-win_amd64.whl (24.3 MB)\n",
      "   ---------------------------------------- 0.0/24.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/24.3 MB 3.0 MB/s eta 0:00:09\n",
      "   ---------------------------------------- 0.3/24.3 MB 3.7 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.7/24.3 MB 5.7 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 1.0/24.3 MB 6.0 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 1.2/24.3 MB 5.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.4/24.3 MB 5.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.4/24.3 MB 5.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.4/24.3 MB 5.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 1.6/24.3 MB 3.9 MB/s eta 0:00:06\n",
      "   --- ------------------------------------ 2.1/24.3 MB 4.7 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 2.3/24.3 MB 4.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.4/24.3 MB 4.6 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.3 MB 4.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.3 MB 4.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.6/24.3 MB 4.4 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 2.7/24.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ---- ----------------------------------- 2.7/24.3 MB 3.7 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.7/24.3 MB 4.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.7/24.3 MB 4.0 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.8/24.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 3.9/24.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.1/24.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 4.2/24.3 MB 3.6 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.4/24.3 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.5/24.3 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.7/24.3 MB 3.5 MB/s eta 0:00:06\n",
      "   ------- -------------------------------- 4.8/24.3 MB 3.5 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.0/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.1/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.3/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   -------- ------------------------------- 5.4/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.6/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.8/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 5.9/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 6.1/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.2/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.4/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 6.5/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 6.7/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 6.9/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.0/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 7.2/24.3 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 7.4/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.5/24.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.6/24.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 7.8/24.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.0/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.1/24.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.3/24.3 MB 3.4 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 8.5/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.6/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 8.8/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 9.0/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.1/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.3/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.5/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 9.7/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 9.8/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.0/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 10.2/24.3 MB 3.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 10.4/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.6/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.7/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ----------------- ---------------------- 10.9/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.1/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.3/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 11.4/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.6/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 11.8/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.0/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 12.1/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.3/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.5/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   -------------------- ------------------- 12.7/24.3 MB 3.4 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 12.9/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.0/24.3 MB 3.7 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 13.2/24.3 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.4/24.3 MB 3.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.6/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 13.8/24.3 MB 3.5 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 14.0/24.3 MB 3.5 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.2/24.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.3/24.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 14.5/24.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.7/24.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 14.9/24.3 MB 3.6 MB/s eta 0:00:03\n",
      "   ------------------------ --------------- 15.1/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.3/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.4/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.6/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 15.8/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.0/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.1/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 16.3/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.5/24.3 MB 3.7 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.7/24.3 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 16.9/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.1/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.3/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.4/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 17.6/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 17.8/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.0/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 18.2/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.4/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.5/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 18.7/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 18.9/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.1/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.3/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 19.5/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.6/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 19.8/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 20.0/24.3 MB 3.8 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.2/24.3 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.4/24.3 MB 3.9 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 20.6/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.7/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 20.9/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.1/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.3/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.5/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.7/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 21.8/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.0/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.2/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.6/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.8/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 22.9/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.1/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.3/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.5/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 23.7/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.0/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.2/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.3/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.3/24.3 MB 3.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.3/24.3 MB 3.7 MB/s eta 0:00:00\n",
      "Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
      "Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "Downloading affine-2.4.0-py3-none-any.whl (15 kB)\n",
      "Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "Installing collected packages: snuggs, affine, cligj, click-plugins, rasterio\n",
      "Successfully installed affine-2.4.0 click-plugins-1.1.1 cligj-0.7.2 rasterio-1.3.10 snuggs-1.4.7\n",
      "Collecting folium\n",
      "  Obtaining dependency information for folium from https://files.pythonhosted.org/packages/ae/6d/18a7546e1748ecdd6ed7cd00d3f183faf1df08bd4f5e5e0eb3e72458b862/folium-0.17.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading folium-0.17.0-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting branca>=0.6.0 (from folium)\n",
      "  Obtaining dependency information for branca>=0.6.0 from https://files.pythonhosted.org/packages/75/ca/6074ab4a04dd1a503201c18091b3426f3709670115fae316907a97f98d75/branca-0.7.2-py3-none-any.whl.metadata\n",
      "  Downloading branca-0.7.2-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jinja2>=2.9 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from folium) (3.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from folium) (1.24.3)\n",
      "Requirement already satisfied: requests in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from folium) (2.31.0)\n",
      "Requirement already satisfied: xyzservices in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from folium) (2022.9.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from jinja2>=2.9->folium) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from requests->folium) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from requests->folium) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from requests->folium) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\h.p\\anaconda3\\lib\\site-packages (from requests->folium) (2023.7.22)\n",
      "Downloading folium-0.17.0-py2.py3-none-any.whl (108 kB)\n",
      "   ---------------------------------------- 0.0/108.4 kB ? eta -:--:--\n",
      "   ---------------------- ----------------- 61.4/108.4 kB 1.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 108.4/108.4 kB 1.6 MB/s eta 0:00:00\n",
      "Downloading branca-0.7.2-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: branca, folium\n",
      "Successfully installed branca-0.7.2 folium-0.17.0\n"
     ]
    }
   ],
   "source": [
    "!pip install rasterio\n",
    "!pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "XBYVDq1sdHuR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#analysis datatime\n",
    "import datetime as dt\n",
    "from datetime import datetime\n",
    "\n",
    "import folium\n",
    "import rasterio as rio\n",
    "from folium import plugins\n",
    "from folium.plugins import HeatMap\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder #OneHotEncoder\n",
    "\n",
    "#Standardize the feature\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#Classification Models\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "\n",
    "#regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CTohtX5xdOEx"
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 404: Not Found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Get dataset\u001b[39;00m\n\u001b[0;32m      2\u001b[0m temp_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Temperature\u001b[39m\u001b[38;5;132;01m%20F\u001b[39;00m\u001b[38;5;124morecast/temperature.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m temp_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(temp_url)\n\u001b[0;32m      4\u001b[0m temp_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:713\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    710\u001b[0m     codecs\u001b[38;5;241m.\u001b[39mlookup_error(errors)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;66;03m# open URLs\u001b[39;00m\n\u001b[1;32m--> 713\u001b[0m ioargs \u001b[38;5;241m=\u001b[39m _get_filepath_or_buffer(\n\u001b[0;32m    714\u001b[0m     path_or_buf,\n\u001b[0;32m    715\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m    716\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m    717\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m    718\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m    719\u001b[0m )\n\u001b[0;32m    721\u001b[0m handle \u001b[38;5;241m=\u001b[39m ioargs\u001b[38;5;241m.\u001b[39mfilepath_or_buffer\n\u001b[0;32m    722\u001b[0m handles: \u001b[38;5;28mlist\u001b[39m[BaseBuffer]\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:363\u001b[0m, in \u001b[0;36m_get_filepath_or_buffer\u001b[1;34m(filepath_or_buffer, encoding, compression, mode, storage_options)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;66;03m# assuming storage_options is to be interpreted as headers\u001b[39;00m\n\u001b[0;32m    362\u001b[0m req_info \u001b[38;5;241m=\u001b[39m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39mRequest(filepath_or_buffer, headers\u001b[38;5;241m=\u001b[39mstorage_options)\n\u001b[1;32m--> 363\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m urlopen(req_info) \u001b[38;5;28;01mas\u001b[39;00m req:\n\u001b[0;32m    364\u001b[0m     content_encoding \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mheaders\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Encoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m content_encoding \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgzip\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    366\u001b[0m         \u001b[38;5;66;03m# Override compression based on Content-Encoding header\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:265\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    259\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[38;5;124;03mLazy-import wrapper for stdlib urlopen, as that imports a big chunk of\u001b[39;00m\n\u001b[0;32m    261\u001b[0m \u001b[38;5;124;03mthe stdlib.\u001b[39;00m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01murllib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrequest\u001b[39;00m\n\u001b[1;32m--> 265\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39mrequest\u001b[38;5;241m.\u001b[39murlopen(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:216\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    215\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:525\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m processor \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_response\u001b[38;5;241m.\u001b[39mget(protocol, []):\n\u001b[0;32m    524\u001b[0m     meth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(processor, meth_name)\n\u001b[1;32m--> 525\u001b[0m     response \u001b[38;5;241m=\u001b[39m meth(req, response)\n\u001b[0;32m    527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:634\u001b[0m, in \u001b[0;36mHTTPErrorProcessor.http_response\u001b[1;34m(self, request, response)\u001b[0m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;66;03m# According to RFC 2616, \"2xx\" code indicates that the client's\u001b[39;00m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;66;03m# request was successfully received, understood, and accepted.\u001b[39;00m\n\u001b[0;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;241m200\u001b[39m \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m code \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m300\u001b[39m):\n\u001b[1;32m--> 634\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparent\u001b[38;5;241m.\u001b[39merror(\n\u001b[0;32m    635\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp\u001b[39m\u001b[38;5;124m'\u001b[39m, request, response, code, msg, hdrs)\n\u001b[0;32m    637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:563\u001b[0m, in \u001b[0;36mOpenerDirector.error\u001b[1;34m(self, proto, *args)\u001b[0m\n\u001b[0;32m    561\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_err:\n\u001b[0;32m    562\u001b[0m     args \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mdict\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttp_error_default\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m+\u001b[39m orig_args\n\u001b[1;32m--> 563\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;241m*\u001b[39margs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:496\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m handler \u001b[38;5;129;01min\u001b[39;00m handlers:\n\u001b[0;32m    495\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 496\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:643\u001b[0m, in \u001b[0;36mHTTPDefaultErrorHandler.http_error_default\u001b[1;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[0;32m    642\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhttp_error_default\u001b[39m(\u001b[38;5;28mself\u001b[39m, req, fp, code, msg, hdrs):\n\u001b[1;32m--> 643\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(req\u001b[38;5;241m.\u001b[39mfull_url, code, msg, hdrs, fp)\n",
      "\u001b[1;31mHTTPError\u001b[0m: HTTP Error 404: Not Found"
     ]
    }
   ],
   "source": [
    "#Get dataset\n",
    "temp_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Temperature%20Forecast/temperature.csv'\n",
    "temp_df = pd.read_csv(temp_url)\n",
    "temp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8-OgTJMHeIto"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m temp_df\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m      2\u001b[0m temp_df\u001b[38;5;241m.\u001b[39minfo()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp_df' is not defined"
     ]
    }
   ],
   "source": [
    "temp_df.shape\n",
    "temp_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "YxTq_aWZjP-5"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#extract the  date object into day,month, year format\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m      3\u001b[0m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mday\n\u001b[0;32m      4\u001b[0m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmonth\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m temp_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mmonth\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp_df' is not defined"
     ]
    }
   ],
   "source": [
    "#extract the  date object into day,month, year format\n",
    "temp_df['Date'] = pd.to_datetime(temp_df['Date'])\n",
    "temp_df['day'] = temp_df['Date'].dt.day\n",
    "temp_df['month'] = temp_df['Date'].dt.month\n",
    "temp_df['year'] = temp_df['Date'].dt.year\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SiKa2Spf-iAg"
   },
   "outputs": [],
   "source": [
    "temp_df.drop(['Date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "74HuDLGzjX_O"
   },
   "outputs": [],
   "source": [
    "temp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "751WTFo-B3aD"
   },
   "outputs": [],
   "source": [
    "temp_df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r-bwnDmA99ET"
   },
   "outputs": [],
   "source": [
    "temp_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQDvGMVYAMs2"
   },
   "outputs": [],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_p6SNzMIAh8k"
   },
   "outputs": [],
   "source": [
    "#Im using mean to filling the missing values\n",
    "temp_df.fillna(temp_df.mean(),inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l6YXwWOUHSmz"
   },
   "outputs": [],
   "source": [
    "temp_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LEM9-5FHHWnY"
   },
   "outputs": [],
   "source": [
    "temp_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x7h-gaQhHbhk"
   },
   "outputs": [],
   "source": [
    "temp_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Jn-iZuHH-Tq"
   },
   "outputs": [],
   "source": [
    "#correlation matrix\n",
    "\n",
    "corr_matrix = temp_df.corr()\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yzYrYKCHIxT2"
   },
   "outputs": [],
   "source": [
    "corr_matrix = temp_df.corr()\n",
    "\n",
    "#plotting the heatmap\n",
    "plt.figure(figsize=(20,15))\n",
    "sns.heatmap(corr_matrix,annot= True,cmap = 'coolwarm')\n",
    "plt.title = 'Correlation Matrix'\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPaI0kZXsql5"
   },
   "source": [
    "As per the above correlation  :\n",
    " **Next_Tmax** is highly Possitive correlation with\n",
    "\n",
    " Present_Tmax(.61),\n",
    "\n",
    " Present_Tmin(0.47),\n",
    "\n",
    " LDAPS_Tmax_lapse(0.83),\n",
    "\n",
    " LDAPS_Tmin_lapse(0.59),\n",
    "\n",
    " Next_Tmin(0.62),   \n",
    "\n",
    "Negitive:\n",
    " LDAPS_RHmin(-0.44),.\n",
    "  \n",
    "    and\n",
    "    \n",
    "  **Next_tmin** have higly correlation with -**Possitive**\n",
    "  Present_Tmax(0.62),\n",
    "\n",
    "  Present_Tmin(0.8),\n",
    "\n",
    "  LDAPS_Tmin_lapse(0.88),\n",
    "\n",
    "  LDAPS_Tmax_lapse(0.59)\n",
    "\n",
    "  and\n",
    "  \n",
    "  **Solar Radiation **\n",
    "  is highly negitive correlation with month (-0.84)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RHzfGQHstp1y"
   },
   "source": [
    "based on above correlation Data ,we are selecting features for predections\n",
    "\n",
    "present_Tmax, present_Tmin,\n",
    "LDAPS_RHmin,\n",
    "LDAPS_Tmax_lapse\n",
    "LDAPS_Tmax_lapse\n",
    "Next_Tmin\n",
    "\n",
    "and for Next_tmin\n",
    " present_Tmax,Present_tmin,LDAPS_Tmin_lapse,\n",
    " Ldaps_Tmax_lapse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xplNHrj8gYmm"
   },
   "outputs": [],
   "source": [
    "temp_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VeIQaNaHgvR0"
   },
   "outputs": [],
   "source": [
    "#ploting all the column values\n",
    "temp_df.plot(subplots=True,figsize=(25,20))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ryIpUVgJij-O"
   },
   "outputs": [],
   "source": [
    "#temperature Hist plot\n",
    "\n",
    "temp_df.hist(figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TvbRVpmiu7iW"
   },
   "outputs": [],
   "source": [
    "#check the skewness\n",
    "skew_df = temp_df.skew()\n",
    "skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9XjCLP_WvvGx"
   },
   "source": [
    "**Highest possitive skewness : **\n",
    "station             0.000000\n",
    "\n",
    "LDAPS_RHmin         0.300220\n",
    "\n",
    "LDAPS_WS            1.579236\n",
    "\n",
    "  **Moderately possitive skewed :**\n",
    "\n",
    "##LDAPS_LH            0.673757\n",
    "\n",
    "##LDAPS_CC1           0.459458  \n",
    "\n",
    "##LDAPS_CC2           0.472350\n",
    "\n",
    "##LDAPS_CC3           0.640735\n",
    "\n",
    "##LDAPS_CC4           0.666482\n",
    "\n",
    "LDAPS_PPT1          5.393821\n",
    "LDAPS_PPT2          5.775355\n",
    "LDAPS_PPT3          6.457129\n",
    "LDAPS_PPT4          6.825464\n",
    "lat                 0.087062\n",
    "year                0.000000\n",
    "DEM                 1.723257\n",
    "Slope               1.563020\n",
    "\n",
    "**Negitive Skewness :  **\n",
    "lon                -0.285213\n",
    "\n",
    "Solar radiation    -0.511210\n",
    "Next_Tmax          -0.340200\n",
    "Next_Tmin          -0.404447\n",
    "day                -0.008926\n",
    "month              -0.195889\n",
    "Present_Tmax       -0.264137\n",
    "Present_Tmin       -0.367538\n",
    "\n",
    "LDAPS_RHmax        -0.855015\n",
    "LDAPS_Tmax_lapse   -0.227880\n",
    "LDAPS_Tmin_lapse   -0.581763"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Mur7rQWZxRw6"
   },
   "outputs": [],
   "source": [
    "#Log transformation of the data\n",
    "#plan to redusing the positive skewness\n",
    "\n",
    "skewness_colums = ['LDAPS_WS','LDAPS_LH','LDAPS_CC1','LDAPS_CC2',\n",
    "                   'LDAPS_CC3','LDAPS_CC4','LDAPS_PPT1',\n",
    "                   'LDAPS_PPT2','LDAPS_PPT3','LDAPS_PPT4','DEM','Slope']\n",
    "for col in skewness_colums:\n",
    "  temp_df[col] = np.log(temp_df[col]+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2oqMrvPfzXlp"
   },
   "outputs": [],
   "source": [
    "#after log transformation skewness\n",
    "\n",
    "skew_df = temp_df.skew()\n",
    "skew_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-tmR5Tpoz5-d"
   },
   "source": [
    "The log transfermation has reduced the skewness for servera features ,sitll some remain highly skewed .\n",
    "\n",
    "#we will try with another Box-Cox or squared Root method  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ia54Gfdy0h_p"
   },
   "outputs": [],
   "source": [
    "#applying Box_cox  transsfermation\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "boxcox_colums = ['LDAPS_PPT1','LDAPS_PPT2','LDAPS_PPT3','LDAPS_PPT4']\n",
    "for col in boxcox_colums:\n",
    "  temp_df[col], _= boxcox(temp_df[col]+1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ahGkq2841xuS"
   },
   "outputs": [],
   "source": [
    "skew_df = temp_df.skew()\n",
    "skew_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iQfA7FEy7pn3"
   },
   "outputs": [],
   "source": [
    "tem_compar = temp_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u1K-wPVA71MD"
   },
   "outputs": [],
   "source": [
    "compare_tem = tem_compar.loc['2013': '2017']\n",
    "compare_tem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "boNcsJww1Jt2"
   },
   "outputs": [],
   "source": [
    "#scatter plot\n",
    "sns.scatterplot(x='Present_Tmax',y='Next_Tmax',data=compare_tem)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bvZSxOJp9jRE"
   },
   "outputs": [],
   "source": [
    "#split the data\n",
    "features  = temp_df.drop(['Next_Tmax','Next_Tmin'],axis=1)\n",
    "target_max = temp_df['Next_Tmax']\n",
    "target_min = temp_df['Next_Tmin']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KIztFGhp7F7M"
   },
   "outputs": [],
   "source": [
    "missing_val = features.isnull().sum()\n",
    "missing_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wgd3LvzB8E41"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "features = imputer.fit_transform(features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKi1lBK43mUl"
   },
   "outputs": [],
   "source": [
    "#Splitting the data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "X_train_max,X_test_max,y_train_max,y_test_max = train_test_split(features,target_max,test_size=0.2,random_state=42)\n",
    "X_train_min,X_test_min,y_train_min,y_test_min = train_test_split(features,target_min,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3dnDGPYi3-vi"
   },
   "outputs": [],
   "source": [
    "#scalling the data\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_max = scaler.fit_transform(X_train_max)\n",
    "X_test_max = scaler.transform(X_test_max)\n",
    "\n",
    "X_train_min = scaler.fit_transform(X_train_min)\n",
    "X_test_min = scaler.transform(X_test_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "drHWeqnO6EAN"
   },
   "outputs": [],
   "source": [
    "#model building  for Max\n",
    "\n",
    "models = [LinearRegression(),\n",
    "          Ridge(alpha = 0.001),\n",
    "          Lasso(alpha=0.003),\n",
    "          SVR(),\n",
    "          DecisionTreeRegressor(),\n",
    "          RandomForestRegressor(),\n",
    "          GradientBoostingRegressor(),\n",
    "          AdaBoostRegressor(base_estimator=LinearRegression())]\n",
    "\n",
    "model_names = ['LinearRegression','Ridge','Lasso','SVR','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor']\n",
    "tmp_model_df = pd.DataFrame(columns = ['Model_name','MSE','R2', 'MeanCV'])\n",
    "for model,model_names in zip(models,model_names):\n",
    "  model.fit(X_train_max,y_train_max)\n",
    "  pred = model.predict(X_test_max)\n",
    "  mse = mean_squared_error(y_test_max,pred)\n",
    "  r2 = r2_score(y_test_max,pred)\n",
    "  mean_cv = cross_val_score(model,X_train_max,y_train_max,cv=5).mean()\n",
    "  tmp_model_df = pd.concat([tmp_model_df,pd.DataFrame({'Model_name':[model_names],'MSE':[mse],'R2':[r2],'MeanCV':[mean_cv]})],ignore_index=True)\n",
    "tmp_model_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rTUZvo_m9qu_"
   },
   "source": [
    "\tModel_name\tMSE\tR2\tMeanCV\n",
    "0\tLinearRegression\t2.269422\t0.767641\t0.764176\n",
    "\n",
    "1\tRidge\t2.269422\t0.767641\t0.764176\n",
    "\n",
    "2\tLasso\t2.271593\t0.767419\t0.764001\n",
    "\n",
    "3\tSVR\t1.009534\t0.896637\t0.878005\n",
    "\n",
    "4\tDecisionTreeRegressor\t2.147772\t0.780096\t0.747639\n",
    "\n",
    "##5\tRandomForestRegressor\t0.827086\t0.915317\t0.896692\n",
    "\n",
    "6\tGradientBoostingRegressor\t1.337337\t0.863074\t0.848335\n",
    "\n",
    "7\tAdaBoostRegressor\t2.403693\t0.753893\t0.750541\n",
    "\n",
    "\n",
    "\n",
    "as per the above models  is have best performance with the lowest MSE and highest R2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhrMvVdE-gom"
   },
   "source": [
    "**Hyperparameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8ntRfAtn-mRN"
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i8bqRy1v-0_I"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "rf_model = RandomForestRegressor(random_state = 42)\n",
    "grid_search = GridSearchCV(estimator = rf_model, param_grid = param_grid, cv=3,scoring = 'neg_mean_squared_error',verbose =2,n_jobs= -1)\n",
    "grid_search.fit(X_train_max, y_train_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Ug0rsVeEYDA"
   },
   "outputs": [],
   "source": [
    "#Best parameters and model :\n",
    "best_params = grid_search.best_params_\n",
    "best_model = grid_search.best_estimator_\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(\"Best Model:\", best_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AWsPRDwnSd7o"
   },
   "outputs": [],
   "source": [
    "#deploy best_model using best parameters\n",
    "\n",
    "rf_model_best = RandomForestRegressor(max_depth=20,min_samples_leaf=1,min_samples_split=2,n_estimators=200)\n",
    "rf_model_best.fit(X_train_max,y_train_max)\n",
    "pred_best = rf_model_best.predict(X_test_max)\n",
    "\n",
    "mse_max = mean_squared_error(y_test_max,pred_best)\n",
    "r2_max = r2_score(y_test_max,pred_best)\n",
    "\n",
    "print(\"MSE:\", mse_max)\n",
    "print(\"R2:\", r2_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8xeyoPdxRRLf"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(rf_model_best,'rf_model_best.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uurIFrLuUQEj"
   },
   "source": [
    "**#model building  for Min**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RNtCL2x8URjK"
   },
   "outputs": [],
   "source": [
    "#model building  for Min\n",
    "\n",
    "models_min = [LinearRegression(),\n",
    "            Ridge(alpha = 0.001),\n",
    "            Lasso(alpha=0.003),\n",
    "            SVR(),\n",
    "            DecisionTreeRegressor(),\n",
    "            RandomForestRegressor(),\n",
    "            GradientBoostingRegressor(),\n",
    "            AdaBoostRegressor(base_estimator=LinearRegression())]\n",
    "\n",
    "model_names_min = ['LinearRegression','Ridge','Lasso','SVR','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor']\n",
    "\n",
    "tmp_model_df = pd.DataFrame(columns = ['MSE','R2', 'MeanCV'])\n",
    "\n",
    "for model,model_names_min in zip(models_min,model_names_min):\n",
    "  model.fit(X_train_min,y_train_min)\n",
    "  pred_min = model.predict(X_test_min)\n",
    "  mse = mean_squared_error(y_test_min,pred_min)\n",
    "  r2 = r2_score(y_test_min,pred_min)\n",
    "  mean_cv = cross_val_score(model,X_train_min,y_train_min,cv=5).mean()\n",
    "  tmp_model_df = pd.concat([tmp_model_df,pd.DataFrame({'model_names':[model_names_min],'MSE':[mse],'R2':[r2],'MeanCV':[mean_cv]})],ignore_index=True)\n",
    "tmp_model_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQpzykFe25m0"
   },
   "source": [
    "#Best Model selection\n",
    "Key points and trying to explain as per my understanding  \n",
    "\n",
    "**Lower is better in Mean squared Error**\n",
    "\n",
    "**Higher is better in R-squared value**\n",
    "\n",
    "**Higher value is better in Mean Cross validation Score**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## 1. 0.486753\t0.921890\t0.905323\tSVR\n",
    "Here in SVC( support vector Regressor the values are given to see best performance model for predection\n",
    "\n",
    "\n",
    "and next best model is :\n",
    "\n",
    "# 0.570188\t0.908501\t0.899237\tRandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E3lxSGoh4hJX"
   },
   "source": [
    "Now I'm going to select first best performance model is **SVR** and second best performance models **RandomForestRegressor**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ld4XRWfo69i0"
   },
   "outputs": [],
   "source": [
    "#for SVR model :\n",
    "#Parameter grid for SVR\n",
    "\n",
    "param_grid = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto'],\n",
    "    'epsilon': [0.01, 0.1, 1]\n",
    "\n",
    "}\n",
    "\n",
    "svr =SVR()\n",
    "grid_search = GridSearchCV(estimator=svr,param_grid=param_grid,cv=3,n_jobs=-1, verbose=2,scoring= 'neg_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train_min,y_train_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w-2eLPDjBC-x"
   },
   "outputs": [],
   "source": [
    "best_params = grid_search.best_params_\n",
    "print(f'Best parameters :{best_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F_6Zq4R546OG"
   },
   "outputs": [],
   "source": [
    "#Best SVR\n",
    "svr_best  = SVR(C = 10, epsilon =  0.1, gamma = 'scale', kernel = 'rbf')\n",
    "svr_best.fit(X_train_min,y_train_min)\n",
    "\n",
    "y_train_min_pred = svr_best.predict(X_train_min)\n",
    "y_test_pred = svr_best.predict(X_test_min)\n",
    "\n",
    "\n",
    "print(y_train_min_pred)\n",
    "print(y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tEqbDQV4OFmO"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "mse_train = mean_squared_error(y_train_min,y_train_min_pred)\n",
    "mae_train = mean_squared_error(y_train_min,y_train_min_pred)\n",
    "r2_train_test = r2_score(y_train_min,y_train_min_pred)\n",
    "\n",
    "\n",
    "mse_test = mean_squared_error(y_test_min,y_test_pred)\n",
    "mae_test = mean_squared_error(y_test_min,y_test_pred)\n",
    "r2_test = r2_score(y_test_min,y_test_pred)\n",
    "\n",
    "print(f'MSE_train : {mse_train}')\n",
    "print(f'MAE_train : {mae_train}')\n",
    "print(f'R2_train : {r2_train_test}')\n",
    "\n",
    "print(f'MSE_test : {mse_test}')\n",
    "print(f'MAE_test : {mae_test}')\n",
    "print(f'R2_test : {r2_test}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NjdgDa4aQyDs"
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(svr_best,'svr_model.pkl')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "include_colab_link": true,
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
