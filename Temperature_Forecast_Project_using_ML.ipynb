{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/datatrained_inter_public/blob/main/Temperature_Forecast_Project_using_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-K-wP2AyThw1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Project Description**\n",
        "This data is for the purpose of bias correction of next-day maximum and minimum air temperatures forecast of the LDAPS model operated by the Korea Meteorological Administration over Seoul, South Korea. This data consists of summer data from 2013 to 2017. The input data is largely composed of the LDAPS model's next-day forecast data, in-situ maximum and minimum temperatures of present-day, and geographic auxiliary variables. There are two outputs (i.e. next-day maximum and minimum air temperatures) in this data. Hindcast validation was conducted for the period from 2015 to 2017.\n",
        "\n",
        "**Attribute Information:**\n",
        "For more information, read [Cho et al, 2020].\n",
        "1. station - used weather station number: 1 to 25\n",
        "2. Date - Present day: yyyy-mm-dd ('2013-06-30' to '2017-08-30')\n",
        "3. Present_Tmax - Maximum air temperature between 0 and 21 h on the present day (Â°C): 20 to 37.6\n",
        "4. Present_Tmin - Minimum air temperature between 0 and 21 h on the present day (Â°C): 11.3 to 29.9\n",
        "5. LDAPS_RHmin - LDAPS model forecast of next-day minimum relative humidity (%): 19.8 to 98.5\n",
        "6. LDAPS_RHmax - LDAPS model forecast of next-day maximum relative humidity (%): 58.9 to 100\n",
        "7. LDAPS_Tmax_lapse - LDAPS model forecast of next-day maximum air temperature applied lapse rate (Â°C): 17.6 to 38.5\n",
        "8. LDAPS_Tmin_lapse - LDAPS model forecast of next-day minimum air temperature applied lapse rate (Â°C): 14.3 to 29.6\n",
        "9. LDAPS_WS - LDAPS model forecast of next-day average wind speed (m/s): 2.9 to 21.9\n",
        "10. LDAPS_LH - LDAPS model forecast of next-day average latent heat flux (W/m2): -13.6 to 213.4\n",
        "11. LDAPS_CC1 - LDAPS model forecast of next-day 1st 6-hour split average cloud cover (0-5 h) (%): 0 to 0.97\n",
        "12. LDAPS_CC2 - LDAPS model forecast of next-day 2nd 6-hour split average cloud cover (6-11 h) (%): 0 to 0.97\n",
        "13. LDAPS_CC3 - LDAPS model forecast of next-day 3rd 6-hour split average cloud cover (12-17 h) (%): 0 to 0.98\n",
        "14. LDAPS_CC4 - LDAPS model forecast of next-day 4th 6-hour split average cloud cover (18-23 h) (%): 0 to 0.97\n",
        "15. LDAPS_PPT1 - LDAPS model forecast of next-day 1st 6-hour split average precipitation (0-5 h) (%): 0 to 23.7\n",
        "16. LDAPS_PPT2 - LDAPS model forecast of next-day 2nd 6-hour split average precipitation (6-11 h) (%): 0 to 21.6\n",
        "17. LDAPS_PPT3 - LDAPS model forecast of next-day 3rd 6-hour split average precipitation (12-17 h) (%): 0 to 15.8\n",
        "18. LDAPS_PPT4 - LDAPS model forecast of next-day 4th 6-hour split average precipitation (18-23 h) (%): 0 to 16.7\n",
        "19. lat - Latitude (Â°): 37.456 to 37.645\n",
        "20. lon - Longitude (Â°): 126.826 to 127.135\n",
        "21. DEM - Elevation (m): 12.4 to 212.3\n",
        "22. Slope - Slope (Â°): 0.1 to 5.2\n",
        "23. Solar radiation - Daily incoming solar radiation (wh/m2): 4329.5 to 5992.9\n",
        "24. Next_Tmax - The next-day maximum air temperature (Â°C): 17.4 to 38.9\n",
        "25. Next_Tmin - The next-day minimum air temperature (Â°C): 11.3 to 29.8T\n",
        "\n",
        "You have to build separate models that can predict the minimum temperature for the next day and the maximum temperature for the next day based on the details provided in the dataset.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8KV7ZZmZTlHP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataset Link-**\n",
        "•\thttps://github.com/FlipRoboTechnologies/ML_-Datasets/blob/main/Temperature%20Forecast/temperature.csv\n"
      ],
      "metadata": {
        "id": "Y9cTuQ7aTwDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install rasterio\n",
        "!pip install folium"
      ],
      "metadata": {
        "id": "z330L2hmci4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "#analysis datatime\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "\n",
        "import folium\n",
        "import rasterio as rio\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder #OneHotEncoder\n",
        "\n",
        "#Standardize the feature\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "#Classification Models\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "\n",
        "#regression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "XBYVDq1sdHuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Get dataset\n",
        "temp_url = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Temperature%20Forecast/temperature.csv'\n",
        "temp_df = pd.read_csv(temp_url)\n",
        "temp_df.head()"
      ],
      "metadata": {
        "id": "CTohtX5xdOEx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.shape\n",
        "temp_df.info()"
      ],
      "metadata": {
        "id": "8-OgTJMHeIto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#extract the  date object into day,month, year format\n",
        "temp_df['Date'] = pd.to_datetime(temp_df['Date'])\n",
        "temp_df['day'] = temp_df['Date'].dt.day\n",
        "temp_df['month'] = temp_df['Date'].dt.month\n",
        "temp_df['year'] = temp_df['Date'].dt.year\n",
        "temp_df.head()\n"
      ],
      "metadata": {
        "id": "YxTq_aWZjP-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.drop(['Date'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "SiKa2Spf-iAg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "74HuDLGzjX_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.duplicated().sum()"
      ],
      "metadata": {
        "id": "751WTFo-B3aD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.sample(5)"
      ],
      "metadata": {
        "id": "r-bwnDmA99ET"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.describe()"
      ],
      "metadata": {
        "id": "EQDvGMVYAMs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Im using mean to filling the missing values\n",
        "temp_df.fillna(temp_df.mean(),inplace=True)\n"
      ],
      "metadata": {
        "id": "_p6SNzMIAh8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.isnull().sum()"
      ],
      "metadata": {
        "id": "l6YXwWOUHSmz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.shape"
      ],
      "metadata": {
        "id": "LEM9-5FHHWnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.describe()"
      ],
      "metadata": {
        "id": "x7h-gaQhHbhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#correlation matrix\n",
        "\n",
        "corr_matrix = temp_df.corr()\n",
        "corr_matrix"
      ],
      "metadata": {
        "id": "0Jn-iZuHH-Tq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corr_matrix = temp_df.corr()\n",
        "\n",
        "#plotting the heatmap\n",
        "plt.figure(figsize=(20,15))\n",
        "sns.heatmap(corr_matrix,annot= True,cmap = 'coolwarm')\n",
        "plt.title = 'Correlation Matrix'\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yzYrYKCHIxT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As per the above correlation  :\n",
        " **Next_Tmax** is highly Possitive correlation with\n",
        "\n",
        " Present_Tmax(.61),\n",
        "\n",
        " Present_Tmin(0.47),\n",
        "\n",
        " LDAPS_Tmax_lapse(0.83),\n",
        "\n",
        " LDAPS_Tmin_lapse(0.59),\n",
        "\n",
        " Next_Tmin(0.62),   \n",
        "\n",
        "Negitive:\n",
        " LDAPS_RHmin(-0.44),.\n",
        "  \n",
        "    and\n",
        "    \n",
        "  **Next_tmin** have higly correlation with -**Possitive**\n",
        "  Present_Tmax(0.62),\n",
        "\n",
        "  Present_Tmin(0.8),\n",
        "\n",
        "  LDAPS_Tmin_lapse(0.88),\n",
        "\n",
        "  LDAPS_Tmax_lapse(0.59)\n",
        "\n",
        "  and\n",
        "  \n",
        "  **Solar Radiation **\n",
        "  is highly negitive correlation with month (-0.84)\n",
        "\n"
      ],
      "metadata": {
        "id": "ZPaI0kZXsql5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "based on above correlation Data ,we are selecting features for predections\n",
        "\n",
        "present_Tmax, present_Tmin,\n",
        "LDAPS_RHmin,\n",
        "LDAPS_Tmax_lapse\n",
        "LDAPS_Tmax_lapse\n",
        "Next_Tmin\n",
        "\n",
        "and for Next_tmin\n",
        " present_Tmax,Present_tmin,LDAPS_Tmin_lapse,\n",
        " Ldaps_Tmax_lapse\n"
      ],
      "metadata": {
        "id": "RHzfGQHstp1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp_df.columns"
      ],
      "metadata": {
        "id": "xplNHrj8gYmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ploting all the column values\n",
        "temp_df.plot(subplots=True,figsize=(25,20))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VeIQaNaHgvR0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#temperature Hist plot\n",
        "\n",
        "temp_df.hist(figsize=(15,10))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ryIpUVgJij-O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#check the skewness\n",
        "skew_df = temp_df.skew()\n",
        "skew_df"
      ],
      "metadata": {
        "id": "TvbRVpmiu7iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Highest possitive skewness : **\n",
        "station             0.000000\n",
        "\n",
        "LDAPS_RHmin         0.300220\n",
        "\n",
        "LDAPS_WS            1.579236\n",
        "\n",
        "  **Moderately possitive skewed :**\n",
        "\n",
        "##LDAPS_LH            0.673757\n",
        "\n",
        "##LDAPS_CC1           0.459458  \n",
        "\n",
        "##LDAPS_CC2           0.472350\n",
        "\n",
        "##LDAPS_CC3           0.640735\n",
        "\n",
        "##LDAPS_CC4           0.666482\n",
        "\n",
        "LDAPS_PPT1          5.393821\n",
        "LDAPS_PPT2          5.775355\n",
        "LDAPS_PPT3          6.457129\n",
        "LDAPS_PPT4          6.825464\n",
        "lat                 0.087062\n",
        "year                0.000000\n",
        "DEM                 1.723257\n",
        "Slope               1.563020\n",
        "\n",
        "**Negitive Skewness :  **\n",
        "lon                -0.285213\n",
        "\n",
        "Solar radiation    -0.511210\n",
        "Next_Tmax          -0.340200\n",
        "Next_Tmin          -0.404447\n",
        "day                -0.008926\n",
        "month              -0.195889\n",
        "Present_Tmax       -0.264137\n",
        "Present_Tmin       -0.367538\n",
        "\n",
        "LDAPS_RHmax        -0.855015\n",
        "LDAPS_Tmax_lapse   -0.227880\n",
        "LDAPS_Tmin_lapse   -0.581763"
      ],
      "metadata": {
        "id": "9XjCLP_WvvGx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Log transformation of the data\n",
        "#plan to redusing the positive skewness\n",
        "\n",
        "skewness_colums = ['LDAPS_WS','LDAPS_LH','LDAPS_CC1','LDAPS_CC2',\n",
        "                   'LDAPS_CC3','LDAPS_CC4','LDAPS_PPT1',\n",
        "                   'LDAPS_PPT2','LDAPS_PPT3','LDAPS_PPT4','DEM','Slope']\n",
        "for col in skewness_colums:\n",
        "  temp_df[col] = np.log(temp_df[col]+1)"
      ],
      "metadata": {
        "id": "Mur7rQWZxRw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#after log transformation skewness\n",
        "\n",
        "skew_df = temp_df.skew()\n",
        "skew_df"
      ],
      "metadata": {
        "id": "2oqMrvPfzXlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The log transfermation has reduced the skewness for servera features ,sitll some remain highly skewed .\n",
        "\n",
        "#we will try with another Box-Cox or squared Root method  \n",
        "\n"
      ],
      "metadata": {
        "id": "-tmR5Tpoz5-d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#applying Box_cox  transsfermation\n",
        "from scipy.stats import boxcox\n",
        "\n",
        "boxcox_colums = ['LDAPS_PPT1','LDAPS_PPT2','LDAPS_PPT3','LDAPS_PPT4']\n",
        "for col in boxcox_colums:\n",
        "  temp_df[col], _= boxcox(temp_df[col]+1)\n"
      ],
      "metadata": {
        "id": "Ia54Gfdy0h_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skew_df = temp_df.skew()\n",
        "skew_df"
      ],
      "metadata": {
        "id": "ahGkq2841xuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tem_compar = temp_df.copy()"
      ],
      "metadata": {
        "id": "iQfA7FEy7pn3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_tem = tem_compar.loc['2013': '2017']\n",
        "compare_tem"
      ],
      "metadata": {
        "id": "u1K-wPVA71MD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot\n",
        "sns.scatterplot(x='Present_Tmax',y='Next_Tmax',data=compare_tem)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "boNcsJww1Jt2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split the data\n",
        "features  = temp_df.drop(['Next_Tmax','Next_Tmin'],axis=1)\n",
        "target_max = temp_df['Next_Tmax']\n",
        "target_min = temp_df['Next_Tmin']\n",
        "\n"
      ],
      "metadata": {
        "id": "bvZSxOJp9jRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "missing_val = features.isnull().sum()\n",
        "missing_val"
      ],
      "metadata": {
        "id": "KIztFGhp7F7M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import KNNImputer\n",
        "imputer = KNNImputer(n_neighbors=5)\n",
        "features = imputer.fit_transform(features)\n",
        "\n"
      ],
      "metadata": {
        "id": "wgd3LvzB8E41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the data\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import r2_score\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "\n",
        "X_train_max,X_test_max,y_train_max,y_test_max = train_test_split(features,target_max,test_size=0.2,random_state=42)\n",
        "X_train_min,X_test_min,y_train_min,y_test_min = train_test_split(features,target_min,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "rKi1lBK43mUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#scalling the data\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train_max = scaler.fit_transform(X_train_max)\n",
        "X_test_max = scaler.transform(X_test_max)\n",
        "\n",
        "X_train_min = scaler.fit_transform(X_train_min)\n",
        "X_test_min = scaler.transform(X_test_min)"
      ],
      "metadata": {
        "id": "3dnDGPYi3-vi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model building  for Max\n",
        "\n",
        "models = [LinearRegression(),\n",
        "          Ridge(alpha = 0.001),\n",
        "          Lasso(alpha=0.003),\n",
        "          SVR(),\n",
        "          DecisionTreeRegressor(),\n",
        "          RandomForestRegressor(),\n",
        "          GradientBoostingRegressor(),\n",
        "          AdaBoostRegressor(base_estimator=LinearRegression())]\n",
        "\n",
        "model_names = ['LinearRegression','Ridge','Lasso','SVR','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor']\n",
        "tmp_model_df = pd.DataFrame(columns = ['Model_name','MSE','R2', 'MeanCV'])\n",
        "for model,model_names in zip(models,model_names):\n",
        "  model.fit(X_train_max,y_train_max)\n",
        "  pred = model.predict(X_test_max)\n",
        "  mse = mean_squared_error(y_test_max,pred)\n",
        "  r2 = r2_score(y_test_max,pred)\n",
        "  mean_cv = cross_val_score(model,X_train_max,y_train_max,cv=5).mean()\n",
        "  tmp_model_df = pd.concat([tmp_model_df,pd.DataFrame({'Model_name':[model_names],'MSE':[mse],'R2':[r2],'MeanCV':[mean_cv]})],ignore_index=True)\n",
        "tmp_model_df\n"
      ],
      "metadata": {
        "id": "drHWeqnO6EAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\tModel_name\tMSE\tR2\tMeanCV\n",
        "0\tLinearRegression\t2.269422\t0.767641\t0.764176\n",
        "\n",
        "1\tRidge\t2.269422\t0.767641\t0.764176\n",
        "\n",
        "2\tLasso\t2.271593\t0.767419\t0.764001\n",
        "\n",
        "3\tSVR\t1.009534\t0.896637\t0.878005\n",
        "\n",
        "4\tDecisionTreeRegressor\t2.147772\t0.780096\t0.747639\n",
        "\n",
        "##5\tRandomForestRegressor\t0.827086\t0.915317\t0.896692\n",
        "\n",
        "6\tGradientBoostingRegressor\t1.337337\t0.863074\t0.848335\n",
        "\n",
        "7\tAdaBoostRegressor\t2.403693\t0.753893\t0.750541\n",
        "\n",
        "\n",
        "\n",
        "as per the above models  is have best performance with the lowest MSE and highest R2\n"
      ],
      "metadata": {
        "id": "rTUZvo_m9qu_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter tuning**"
      ],
      "metadata": {
        "id": "NhrMvVdE-gom"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n"
      ],
      "metadata": {
        "id": "8ntRfAtn-mRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "rf_model = RandomForestRegressor(random_state = 42)\n",
        "grid_search = GridSearchCV(estimator = rf_model, param_grid = param_grid, cv=3,scoring = 'neg_mean_squared_error',verbose =2,n_jobs= -1)\n",
        "grid_search.fit(X_train_max, y_train_max)"
      ],
      "metadata": {
        "id": "i8bqRy1v-0_I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best parameters and model :\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "print(\"Best Parameters:\", best_params)\n",
        "print(\"Best Model:\", best_model)\n",
        "\n"
      ],
      "metadata": {
        "id": "5Ug0rsVeEYDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#deploy best_model using best parameters\n",
        "\n",
        "rf_model_best = RandomForestRegressor(max_depth=20,min_samples_leaf=1,min_samples_split=2,n_estimators=200)\n",
        "rf_model_best.fit(X_train_max,y_train_max)\n",
        "pred_best = rf_model_best.predict(X_test_max)\n",
        "\n",
        "mse_max = mean_squared_error(y_test_max,pred_best)\n",
        "r2_max = r2_score(y_test_max,pred_best)\n",
        "\n",
        "print(\"MSE:\", mse_max)\n",
        "print(\"R2:\", r2_max)"
      ],
      "metadata": {
        "id": "AWsPRDwnSd7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(rf_model_best,'rf_model_best.pkl')"
      ],
      "metadata": {
        "id": "8xeyoPdxRRLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**#model building  for Min**"
      ],
      "metadata": {
        "id": "uurIFrLuUQEj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model building  for Min\n",
        "\n",
        "models_min = [LinearRegression(),\n",
        "            Ridge(alpha = 0.001),\n",
        "            Lasso(alpha=0.003),\n",
        "            SVR(),\n",
        "            DecisionTreeRegressor(),\n",
        "            RandomForestRegressor(),\n",
        "            GradientBoostingRegressor(),\n",
        "            AdaBoostRegressor(base_estimator=LinearRegression())]\n",
        "\n",
        "model_names_min = ['LinearRegression','Ridge','Lasso','SVR','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor']\n",
        "\n",
        "tmp_model_df = pd.DataFrame(columns = ['MSE','R2', 'MeanCV'])\n",
        "\n",
        "for model,model_names_min in zip(models_min,model_names_min):\n",
        "  model.fit(X_train_min,y_train_min)\n",
        "  pred_min = model.predict(X_test_min)\n",
        "  mse = mean_squared_error(y_test_min,pred_min)\n",
        "  r2 = r2_score(y_test_min,pred_min)\n",
        "  mean_cv = cross_val_score(model,X_train_min,y_train_min,cv=5).mean()\n",
        "  tmp_model_df = pd.concat([tmp_model_df,pd.DataFrame({'model_names':[model_names_min],'MSE':[mse],'R2':[r2],'MeanCV':[mean_cv]})],ignore_index=True)\n",
        "tmp_model_df"
      ],
      "metadata": {
        "id": "RNtCL2x8URjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Best Model selection\n",
        "Key points and trying to explain as per my understanding  \n",
        "\n",
        "**Lower is better in Mean squared Error**\n",
        "\n",
        "**Higher is better in R-squared value**\n",
        "\n",
        "**Higher value is better in Mean Cross validation Score**\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "## 1. 0.486753\t0.921890\t0.905323\tSVR\n",
        "Here in SVC( support vector Regressor the values are given to see best performance model for predection\n",
        "\n",
        "\n",
        "and next best model is :\n",
        "\n",
        "# 0.570188\t0.908501\t0.899237\tRandomForestRegressor\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zQpzykFe25m0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now I'm going to select first best performance model is **SVR** and second best performance models **RandomForestRegressor**:"
      ],
      "metadata": {
        "id": "E3lxSGoh4hJX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#for SVR model :\n",
        "#Parameter grid for SVR\n",
        "\n",
        "param_grid = {\n",
        "    'kernel': ['rbf'],\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'epsilon': [0.01, 0.1, 1]\n",
        "\n",
        "}\n",
        "\n",
        "svr =SVR()\n",
        "grid_search = GridSearchCV(estimator=svr,param_grid=param_grid,cv=3,n_jobs=-1, verbose=2,scoring= 'neg_mean_squared_error')\n",
        "\n",
        "grid_search.fit(X_train_min,y_train_min)"
      ],
      "metadata": {
        "id": "ld4XRWfo69i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(f'Best parameters :{best_params}')"
      ],
      "metadata": {
        "id": "w-2eLPDjBC-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best SVR\n",
        "svr_best  = SVR(C = 10, epsilon =  0.1, gamma = 'scale', kernel = 'rbf')\n",
        "svr_best.fit(X_train_min,y_train_min)\n",
        "\n",
        "y_train_min_pred = svr_best.predict(X_train_min)\n",
        "y_test_pred = svr_best.predict(X_test_min)\n",
        "\n",
        "\n",
        "print(y_train_min_pred)\n",
        "print(y_test_pred)"
      ],
      "metadata": {
        "id": "F_6Zq4R546OG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "mse_train = mean_squared_error(y_train_min,y_train_min_pred)\n",
        "mae_train = mean_squared_error(y_train_min,y_train_min_pred)\n",
        "r2_train_test = r2_score(y_train_min,y_train_min_pred)\n",
        "\n",
        "\n",
        "mse_test = mean_squared_error(y_test_min,y_test_pred)\n",
        "mae_test = mean_squared_error(y_test_min,y_test_pred)\n",
        "r2_test = r2_score(y_test_min,y_test_pred)\n",
        "\n",
        "print(f'MSE_train : {mse_train}')\n",
        "print(f'MAE_train : {mae_train}')\n",
        "print(f'R2_train : {r2_train_test}')\n",
        "\n",
        "print(f'MSE_test : {mse_test}')\n",
        "print(f'MAE_test : {mae_test}')\n",
        "print(f'R2_test : {r2_test}')"
      ],
      "metadata": {
        "id": "tEqbDQV4OFmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(svr_best,'svr_model.pkl')"
      ],
      "metadata": {
        "id": "NjdgDa4aQyDs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}