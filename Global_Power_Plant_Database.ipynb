{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyOjIbNN8toXbMgeYwa8xAGd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nallagondu/datatrained_inter_public/blob/main/Global_Power_Plant_Database.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u8syGr1J2fAz"
      },
      "outputs": [],
      "source": [
        "!pip install rasterio\n",
        "!pip install folium"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Global Power Plant Database**\n",
        "\n",
        "**Project Description**\n",
        "\n",
        "The Global Power Plant Database is a comprehensive, open source database of power plants around the world. It centralizes power plant data to make it easier to navigate, compare and draw insights for one’s own analysis. The database covers approximately 14,000 power plants from 3 countries(USA, AUS, INDIA) and includes thermal plants (e.g. coal, gas, oil, nuclear, biomass, waste, geothermal) and renewables (e.g. hydro, wind, solar). Each power plant is geolocated and entries contain information on plant capacity, generation, ownership, and fuel type. It will be continuously updated as data becomes available.\n",
        "\n",
        "**Key attributes of the database**\n",
        "\n",
        "**The database includes the following indicators:**\n",
        "\n",
        "•\t`country` (text): 3 character country code corresponding to the ISO 3166-1 alpha-3 specification [5]\n",
        "\n",
        "•\t`country_long` (text): longer form of the country designation\n",
        "\n",
        "•\t`name` (text): name or title of the power plant, generally in Romanized form\n",
        "\n",
        "•\t`gppd_idnr` (text): 10 or 12 character identifier for the power plant\n",
        "\n",
        "•\t`capacity_mw` (number): electrical generating capacity in megawatts\n",
        "\n",
        "•\t`latitude` (number): geolocation in decimal degrees; WGS84 (EPSG:4326)\n",
        "\n",
        "•\t`longitude` (number): geolocation in decimal degrees; WGS84 (EPSG:4326)\n",
        "\n",
        "•\t`primary_fuel` (text): energy source used in primary electricity generation or export\n",
        "\n",
        "•\t`other_fuel1` (text): energy source used in electricity generation or export\n",
        "\n",
        "•\t`other_fuel2` (text): energy source used in electricity generation or export\n",
        "\n",
        "•\t`other_fuel3` (text): energy source used in electricity generation or export\n",
        "\n",
        "•\t `commissioning_year` (number): year of plant operation, weighted by unit-capacity when data is available\n",
        "\n",
        "•\t`owner` (text): majority shareholder of the power plant, generally in Romanized form\n",
        "\n",
        "•\t`source` (text): entity reporting the data; could be an organization, report, or document, generally in Romanized form\n",
        "\n",
        "•\t`url` (text): web document corresponding to the `source` field\n",
        "\n",
        "•\t`geolocation_source` (text): attribution for geolocation information\n",
        "\n",
        "•\t`wepp_id` (text): a reference to a unique plant identifier in the widely-used PLATTS-WEPP database.\n",
        "\n",
        "•\t`year_of_capacity_data` (number): year the capacity information was reported\n",
        "\n",
        "•\t`generation_gwh_2013` (number): electricity generation in gigawatt-hours reported for the year 2013\n",
        "\n",
        "•\t`generation_gwh_2014` (number): electricity generation in gigawatt-hours reported for the year 2014\n",
        "\n",
        "•\t`generation_gwh_2015` (number): electricity generation in gigawatt-hours reported for the year 2015\n",
        "\n",
        "•\t`generation_gwh_2016` (number): electricity generation in gigawatt-hours reported for the year 2016\n",
        "\n",
        "•\t`generation_gwh_2017` (number): electricity generation in gigawatt-hours reported for the year 2017\n",
        "\n",
        "•\t`generation_gwh_2018` (number): electricity generation in gigawatt-hours reported for the year 2018\n",
        "\n",
        "•\t`generation_gwh_2019` (number): electricity generation in gigawatt-hours reported for the year 2019\n",
        "\n",
        "•\t`generation_data_source` (text): attribution for the reported generation information\n",
        "\n",
        "•\t`estimated_generation_gwh_2013` (number): estimated electricity generation in gigawatt-hours for the year 2013\n",
        "\n",
        "•\t`estimated_generation_gwh_2014` (number): estimated electricity generation in gigawatt-hours for the year 2014\n",
        "\n",
        "•\t`estimated_generation_gwh_2015` (number): estimated electricity generation in gigawatt-hours for the year 2015\n",
        "\n",
        "•\t`estimated_generation_gwh_2016` (number): estimated electricity generation in gigawatt-hours for the year 2016\n",
        "\n",
        "•\t`estimated_generation_gwh_2017` (number): estimated electricity generation in gigawatt-hours for the year 2017\n",
        "\n",
        "•\t'estimated_generation_note_2013` (text): label of the model/method used to estimate generation for the year 2013\n",
        "\n",
        "•\t`estimated_generation_note_2014` (text): label of the model/method used to estimate generation for the year 2014\n",
        "\n",
        "•\t`estimated_generation_note_2015` (text): label of the model/method used to estimate generation for the year 2015\n",
        "\n",
        "•\t`estimated_generation_note_2016` (text): label of the model/method used to estimate generation for the year 2016\n",
        "\n",
        "•\t`estimated_generation_note_2017` (text): label of the model/method used to estimate generation for the year 2017\n",
        "\n",
        "**Fuel Type Aggregation**\n",
        "We define the \"Fuel Type\" attribute of our database based on common fuel categories.\n",
        "\n",
        "Prediction :   Make two prediction  1) Primary Fuel    2) capacity_mw\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vuuOEN0V2osr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hint : Use pandas methods to combine all the datasets and then start working on this project.\n",
        "\n",
        "\n",
        "**Dataset Link-**\n",
        "•\thttps://github.com/FlipRoboTechnologies/ML_-Datasets/tree/main/Global%20Power%20Plant%20Database\n"
      ],
      "metadata": {
        "id": "lt-IgpRv3SU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "#analysis datatime\n",
        "import datetime as dt\n",
        "from datetime import datetime\n",
        "\n",
        "import folium\n",
        "import rasterio as rio\n",
        "from folium import plugins\n",
        "from folium.plugins import HeatMap\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "metadata": {
        "id": "9YsOwwGX4msa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "GPP_url_IND = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Global%20Power%20Plant%20Database/database_IND.csv'\n",
        "GPP_url_usa = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Global%20Power%20Plant%20Database/database_USA.csv'\n",
        "GPP_url_AUS = 'https://raw.githubusercontent.com/FlipRoboTechnologies/ML_-Datasets/main/Global%20Power%20Plant%20Database/database_AUS.csv'\n",
        "gpp_IND = pd.read_csv(GPP_url_IND)\n",
        "gpp_USA = pd.read_csv(GPP_url_usa)\n",
        "gpp_AUS = pd.read_csv(GPP_url_AUS)"
      ],
      "metadata": {
        "id": "__11BWpT3XZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(gpp_IND.shape)\n",
        "print(gpp_USA.shape)\n",
        "print(gpp_AUS.shape)\n",
        "\n",
        "print(gpp_IND.head())\n",
        "print(gpp_USA.head())\n",
        "print(gpp_AUS.head())"
      ],
      "metadata": {
        "id": "QIniLLsU4qdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#to club all three data sets we are using concatenation\n",
        "\n",
        "df_GPP = pd.concat([gpp_IND,gpp_USA,gpp_AUS])\n",
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "hbuVfhgBoXy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.columns"
      ],
      "metadata": {
        "id": "cY4Qrf7CvNnW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.info()"
      ],
      "metadata": {
        "id": "W5xvZ-djvmMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.sample(10)"
      ],
      "metadata": {
        "id": "v0XMb-5i9q35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.describe()"
      ],
      "metadata": {
        "id": "Zo_SHnXO-kfb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can find some power plants that has negitive generationof power .\n",
        "it seems  it was by   mistike in the dataset but there are some power plants those consume more energy than they produce"
      ],
      "metadata": {
        "id": "AeMyCVIB-tFU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "JIH0uT4iDuVv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "we found lots of missing values in this dataset and mainly  we can see  estimated_generation_gwh    ,wepp_id, other_fue13,other_fue12,other_fue11  are totally missed .\n",
        "\n",
        "**we are going to invistigate large missing other_fue13,other_fue12 and possibily we have to drop \"estimated_generation_gwh    ,wepp_id, \" this columns from dataset**\n"
      ],
      "metadata": {
        "id": "5wpS20ytN-to"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.duplicated().sum()"
      ],
      "metadata": {
        "id": "AcvENT3-NPgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#impute the missing values\n",
        "# capacity capacity_mw ,latitude ,longitude\n",
        "\n",
        "num_cols = ['capacity_mw','latitude','longitude']\n",
        "df_GPP[num_cols] = df_GPP[num_cols].fillna(df_GPP[num_cols].mean())\n",
        "\n",
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "kAy2ydwMqWfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#impute missing values for catagorical columns with most frequent values\n",
        "\n",
        "catagorical_cols = ['primary_fuel','other_fuel1']\n",
        "if all(col in df_GPP.columns for col in catagorical_cols):\n",
        "    df_GPP[catagorical_cols] = df_GPP[catagorical_cols].fillna(df_GPP[catagorical_cols].mode().iloc[0])\n",
        "    print(df_GPP.isnull().sum())\n",
        "else:\n",
        "  miss_cols = set(catagorical_cols) - set(df_GPP.columns)\n",
        "  print(\"Missing columns:\", miss_cols)\n"
      ],
      "metadata": {
        "id": "4H2Kh1d9q_qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#impute missing values for  numerical columns with median\n",
        "median_cols = ['commissioning_year','year_of_capacity_data']\n",
        "df_GPP[median_cols] = df_GPP[median_cols].fillna(df_GPP[median_cols].median())\n",
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "qnQwkW4meqgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#impute missing values for categorical columns with most frequent value\n",
        "\n",
        "most_frequent_cols = ['owner','geolocation_source']\n",
        "df_GPP[most_frequent_cols] = df_GPP[most_frequent_cols].fillna(df_GPP[most_frequent_cols].mode().iloc[0])"
      ],
      "metadata": {
        "id": "Y6jOs7yOfNJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.isnull().sum()\n",
        "\n"
      ],
      "metadata": {
        "id": "20gSGx7WaKx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "s8tCfpb6akDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Check for consistency\n",
        "#need to check  if the  'generation_gwh' value are consistent across years, example there shouldn't be a drastic increase or descrease with out a reasonable cause.\n",
        "#validation of 'generation_gwh' values  and commissioning_year\n",
        "\n",
        "for year in range(2013,2019):\n",
        "  year_col = f'generation_gwh_{year}'\n",
        "  df_GPP.loc[df_GPP[year_col] < df_GPP['commissioning_year'], year_col] = np.nan\n"
      ],
      "metadata": {
        "id": "Zr9yOPDba88Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.drop(columns=['wepp_id','estimated_generation_gwh'],inplace=True)"
      ],
      "metadata": {
        "id": "Y-O3gqyDclNR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "jufjhexvdIut"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "high_miss_values = ['other_fuel2','other_fuel3']\n",
        "df_GPP.drop(columns=high_miss_values,inplace=True)\n"
      ],
      "metadata": {
        "id": "-wU5VViYdU3t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "APn70RSId7U2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.info()"
      ],
      "metadata": {
        "id": "FHvxWSZad9Sj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "EYHVjuk4eCxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "#impute data columns with 0 where nessaary  or using  strategy\n",
        "ness_cols = [f'generation_gwh_{year}' for  year in range(2013,2019)]\n",
        "imputer_gen = SimpleImputer(strategy='constant', fill_value = 0 )\n",
        "df_GPP[ness_cols] = imputer_gen.fit_transform(df_GPP[ness_cols])"
      ],
      "metadata": {
        "id": "KCposnHLgrUa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "taf0t_Kmizw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP['generation_gwh_2019'].fillna(0, inplace=True)\n",
        "df_GPP['generation_data_source'].fillna('N/A', inplace=True)"
      ],
      "metadata": {
        "id": "Ao7UwFBvi4E7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.isnull().sum()"
      ],
      "metadata": {
        "id": "KITaGiQ8jTL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.to_csv('df_GPP_cleaned_data.csv',index=False)"
      ],
      "metadata": {
        "id": "Tw2wjMYujXs6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Data was cleaned and stored in df_GPP_cleaned_data.csv**"
      ],
      "metadata": {
        "id": "Pz4G9t48jtL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "a5TM6XQtjoNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.describe()"
      ],
      "metadata": {
        "id": "iLq6WufkkzJB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.hist(figsize=(20,15))\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PgPJ716cxbAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fuel details\n",
        "\n",
        "plt.figure(figsize=(15,10))\n",
        "sns.barplot(x='primary_fuel',y='capacity_mw',data=df_GPP)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "aIq7H1Ekx8jn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1OG7ZAHljnRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#scatter plot\n",
        "sns.scatterplot(x=df_GPP.capacity_mw, y = df_GPP.primary_fuel)\n",
        "plt.title('Capacity vs Primary Fuel')\n",
        "plt.xlabel('Capacity')\n",
        "plt.ylabel('Primary Fuel')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yJUEcJgEz2hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Correlation Matrix\n",
        "\n",
        "numerical_df_GPP = df_GPP.select_dtypes(include=['int64', 'float64'])\n",
        "\n",
        "corr_matrix = numerical_df_GPP.corr()\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Matrix')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JDK8RB6J0wUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "as per the above correlation matrix ,there is a positive correlation for capacity_mw and generation_gwh_2014 to generation_gwh_2018 and it's range form  0.78 to .80 and it indicatating higher capacity is associated with higher generation value over these years\n",
        "\n",
        "**Generative growth  accross the different years  : 0.73 to 0.97 .**\n",
        "\n",
        "\n",
        "**Negitive correlation : latiture and longtitude**\n",
        "\n",
        "Feak correlation is  :     \n",
        "**commissioning** year with other featurs\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GAM2rxUD1hjy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Capacity vs genaration analysis\n",
        "years = range(2013,2019)\n",
        "\n",
        "for year in years:\n",
        "  plt.figure(figsize=(10, 6))\n",
        "  sns.scatterplot(x='capacity_mw', y=f'generation_gwh_{year}', data=df_GPP,hue = 'primary_fuel')\n",
        "  plt.title(f'Capacity vs Generation : {year}')\n",
        "  plt.xlabel('Capacity')\n",
        "  plt.ylabel('Generation')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "Mm3Dpy5F3Kii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "SrPftAJb5ns_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP.columns"
      ],
      "metadata": {
        "id": "TKuGxr7Z8L4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder #,OneHotEncoder\n",
        "le = LabelEncoder()\n",
        "#one_hot_en = OneHotEncoder()\n",
        "\n",
        "label_encoder_coulmns = ['country','country_long','name','gppd_idnr','primary_fuel','other_fuel1','geolocation_source','generation_data_source','owner','source','url']\n",
        "#one_hot_encode_columns = ['geolocation_source','generation_data_source']\n",
        "\n"
      ],
      "metadata": {
        "id": "wQWFdi-c7YKE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encode = {}\n",
        "\n",
        "for col in label_encoder_coulmns:\n",
        "  df_GPP[col] = le.fit_transform(df_GPP[col])\n",
        "  label_encode[col] = le"
      ],
      "metadata": {
        "id": "YHG6DasH9E38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#apply One Hot encoding\n",
        "\n",
        "#df_GPP = pd.get_dummies(df_GPP, columns=one_hot_encode_columns)\n",
        "df_GPP.head()"
      ],
      "metadata": {
        "id": "OJMrhrob9-LS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_GPP['generation_gwh_2019'] = pd.to_numeric(df_GPP['generation_gwh_2019'], errors='coerce')"
      ],
      "metadata": {
        "id": "P_XI-pcRAtex"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df_GPP.dtypes"
      ],
      "metadata": {
        "id": "pWHwHwK3_F4m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Feature and target selection\n",
        "features = df_GPP.drop(['primary_fuel','capacity_mw'],axis=1)\n",
        "target_fuel = df_GPP['primary_fuel']\n",
        "target_capacity = df_GPP['capacity_mw']\n"
      ],
      "metadata": {
        "id": "RiNfGOvuds0y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Spliting the data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train_fuel,X_test_fuel,y_train_fuel,y_test_fuel = train_test_split(features,target_fuel,test_size=0.2,random_state=42)\n",
        "X_train_capacity,X_test_capacity,y_train_capacity,y_test_capacity = train_test_split(features,target_capacity,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Mzbue9tVeLPR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Standardize the feature\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_fuel = scaler.fit_transform(X_train_fuel)\n",
        "X_test_fuel = scaler.transform(X_test_fuel)\n",
        "X_train_capacity = scaler.fit_transform(X_train_capacity)\n",
        "X_test_capacity = scaler.transform(X_test_capacity)\n"
      ],
      "metadata": {
        "id": "1SFIYbROfGqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Classifiers for fuel predections\n",
        "\n",
        "#from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import BaggingClassifier"
      ],
      "metadata": {
        "id": "xKaF6mAyfgz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classifiers = {\n",
        "          'svc':SVC(),\n",
        "          'rfc':RandomForestClassifier(),\n",
        "          'knc':KNeighborsClassifier(),\n",
        "          'gau':GaussianNB(),\n",
        "          'dtc' : DecisionTreeClassifier(),\n",
        "          'abc' : AdaBoostClassifier(),\n",
        "          'grd':GradientBoostingClassifier(),\n",
        "          'bagg':BaggingClassifier()\n",
        "}"
      ],
      "metadata": {
        "id": "QVbqH8E4hBxK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train AND evalate classifiers for primary fuel predection\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "\n",
        "X_train_fuel = imputer.fit_transform(X_train_fuel)\n",
        "X_test_fuel = imputer.transform(X_test_fuel)\n",
        "\n",
        "for name, classifier in classifiers.items():\n",
        "  classifier.fit(X_train_fuel,y_train_fuel)\n",
        "  y_pred_fuel = classifier.predict(X_test_fuel)\n",
        "  accuracy = accuracy_score(y_test_fuel,y_pred_fuel)\n",
        "  print(f'{name} : {accuracy}')"
      ],
      "metadata": {
        "id": "q4BGm7TChImb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Result :\n",
        "svc : 0.6973684210526315\n",
        "\n",
        "rfc : 0.83796992481203\n",
        "\n",
        "knc : 0.7090225563909774\n",
        "\n",
        "gau : 0.02706766917293233\n",
        "\n",
        "dtc : 0.7699248120300752\n",
        "\n",
        "abc : 0.37105263157894736\n",
        "\n",
        "grd : 0.8150375939849624\n",
        "\n",
        "bagg : 0.8150375939849624\n",
        "\n",
        "**we  can suggest best model \" Random forest classifier \" got 83.79 % accuracy** .\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7JRzULOHPKgm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train_fuel,y_train_fuel)\n",
        "y_pred_fuel = rfc.predict(X_test_fuel)\n",
        "accuracy = accuracy_score(y_test_fuel,y_pred_fuel)\n",
        "print(f'Random forest classifier : {accuracy}')\n",
        "\n"
      ],
      "metadata": {
        "id": "mOst_thipu4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "joblib.dump(rfc,'best_rfc_model.pkl') # best classification model is randomforest classifier"
      ],
      "metadata": {
        "id": "t9L134vxsv-V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#train AND evalate  for capacity_mw  predection\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression,Lasso,Ridge\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.ensemble import AdaBoostRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "metadata": {
        "id": "ReJoAgiQdwqZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**\"capacity_mw\"  predection using regression  models **"
      ],
      "metadata": {
        "id": "RFH3btj3TVdQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "models = [LinearRegression(),\n",
        "          Ridge(alpha = 0.001),\n",
        "          Lasso(alpha=0.003),\n",
        "          SVR(),\n",
        "          DecisionTreeRegressor(),\n",
        "          RandomForestRegressor(),\n",
        "          GradientBoostingRegressor(),\n",
        "          AdaBoostRegressor(base_estimator=LinearRegression())]\n",
        "\n",
        "model_names = 'LinearRegression','Ridge','Lasso','SVR','SGDRegressor','DecisionTreeRegressor','RandomForestRegressor','GradientBoostingRegressor','AdaBoostRegressor','KNeighborsRegressor','BaggingRegressor'\n",
        "model_df = pd.DataFrame(columns=['Model','MSE','R2','MeanCV'])\n",
        "for model,model_names in zip(models,model_names):\n",
        "  print(model)\n",
        "\n",
        "  model.fit(X_train_capacity,y_train_capacity)\n",
        "  pred = model.predict(X_test_capacity)\n",
        "  mse = mean_squared_error(y_test_capacity,pred,squared=False)\n",
        "  r2 = model.score(X_test_capacity,y_test_capacity)\n",
        "\n",
        "  averages = cross_val_score(model,X_train_capacity,y_train_capacity,cv=5,scoring='neg_mean_squared_error').mean()\n",
        "\n",
        "  model_df = pd.concat([model_df,pd.DataFrame({'Model': [model_names],'MSE':mse,'R2':r2,'MeanCV': [averages]})],ignore_index=True)\n",
        "print(model_df)"
      ],
      "metadata": {
        "id": "Kj2BfbRqOjs1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Based on the above results, we can find the best model**\n",
        "\n",
        "\n",
        "**First Best suggested model:**\n",
        "The decision Treeregression is the best model ,based on it's lowest MSE,highest R square ,and best meanCV score -**DecisionTreeRegressor**  166.833201  0.795335  -18154.799626\n",
        "\n",
        "**Best Second model :**\n",
        "RandomForestRegressor  174.778641  **0.775376**  -19560.574025\n"
      ],
      "metadata": {
        "id": "myMggbrckFOS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Hyperparameter Tuning**"
      ],
      "metadata": {
        "id": "i3P-Dyw1laey"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "dtr = DecisionTreeRegressor()\n",
        "\n",
        "# define the perameter grid\n",
        "\n",
        "Paramet_grid  = {\n",
        "    'max_depth': [None, 5, 10, 15],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "\n",
        "}\n",
        "grid_search = GridSearchCV(dtr,Paramet_grid,cv=5,scoring='neg_mean_squared_error',return_train_score=True)\n",
        "grid_search.fit(X_train_capacity,y_train_capacity)\n",
        "\n"
      ],
      "metadata": {
        "id": "t7w-IBc6laDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Best parameters **"
      ],
      "metadata": {
        "id": "GabY7LUOmnAy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(best_params)"
      ],
      "metadata": {
        "id": "CmeMjc3jmqbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Best parameters\n",
        "best_dtr = DecisionTreeRegressor(max_depth=5,min_samples_leaf=2,min_samples_split=5)\n",
        "best_dtr"
      ],
      "metadata": {
        "id": "fQLqasNPnS62"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Trained the model\n",
        "\n",
        "best_dtr.fit(X_train_capacity,y_train_capacity)\n",
        "y_pred_capacity = best_dtr.predict(X_test_capacity)\n",
        "mse_capacity = mean_squared_error(y_test_capacity,y_pred_capacity,squared=False)\n",
        "r2_capacity = best_dtr.score(X_test_capacity,y_test_capacity)\n",
        "print(f'Decision Tree regression MSE: {mse_capacity},  Decision Tree regression R2: {r2_capacity}')\n",
        "#print(r2_capacity)"
      ],
      "metadata": {
        "id": "ZdlMbtNPnpwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Save the Model**"
      ],
      "metadata": {
        "id": "mFs51uuZok2y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "joblib.dump(rfc,'best_rfc_model.pkl') # best classification model is randomforest classifier\n",
        "joblib.dump(best_dtr,'best_dtr_model.pkl') #best regresion model is Randomforestregressor"
      ],
      "metadata": {
        "id": "Rorh1BvXopZB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}